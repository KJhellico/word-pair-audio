import streamlit as st
from gtts import gTTS
from pydub import AudioSegment
from io import BytesIO

AVAILABLE_LANGS = {
    "–§—Ä–∞–Ω—Ü—É–∑—å–∫–∞": "fr",
    "–†–æ—Å—ñ–π—Å—å–∫–∞": "ru",
    "–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞": "uk"
}

if "history" not in st.session_state:
    st.session_state.history = []

st.title("–û–∑–≤—É—á–µ–Ω–Ω—è –ø–∞—Ä —Å–ª—ñ–≤ –¥–≤–æ–º–∞ –º–æ–≤–∞–º–∏")

col1, col2 = st.columns(2)
with col1:
    lang1 = st.selectbox("–ú–æ–≤–∞ —Å–ø–∏—Å–∫—É 1", list(AVAILABLE_LANGS.keys()), index=0)
with col2:
    lang2 = st.selectbox("–ú–æ–≤–∞ —Å–ø–∏—Å–∫—É 2", list(AVAILABLE_LANGS.keys()), index=1)

lang_code1 = AVAILABLE_LANGS[lang1]
lang_code2 = AVAILABLE_LANGS[lang2]

slow = st.checkbox("–ü–æ–≤—ñ–ª—å–Ω–µ —á–∏—Ç–∞–Ω–Ω—è", value=True)
pause_ms = st.slider("–ü–∞—É–∑–∞ –º—ñ–∂ —Å–ª–æ–≤–∞–º–∏ (–º—Å)", 200, 2000, 500, 100)
repeat_count = st.slider("–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ–≤—Ç–æ—Ä—ñ–≤", 1, 100, 20, 1)
one_by_one = st.checkbox("–ß–∏—Ç–∞—Ç–∏ –ø–æ —Å–ª–æ–≤—É –∑ –∫–æ–∂–Ω–æ—ó –º–æ–≤–∏", value=True)

words1 = st.text_area("–°–ø–∏—Å–æ–∫ —Å–ª—ñ–≤ –º–æ–≤–æ—é 1 (–ø–æ –æ–¥–Ω–æ–º—É –≤ —Ä—è–¥–æ–∫)").strip().splitlines()
words2 = st.text_area("–°–ø–∏—Å–æ–∫ —Å–ª—ñ–≤ –º–æ–≤–æ—é 2 (–ø–æ –æ–¥–Ω–æ–º—É –≤ —Ä—è–¥–æ–∫)").strip().splitlines()


def make_audio_list(words: list[str], lang: str) -> list:
    result = []
    for w in words:
        tts = gTTS(text=w, lang=lang, slow=slow)
        tts.save("tmp.mp3")
        audio = AudioSegment.from_file("tmp.mp3")
        result.append(audio)
    return result


if st.button("üîä –ó–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ –∞—É–¥—ñ–æ"):
    if words1 and words2 and len(words1) != len(words2):
        st.error("‚ùå –°–ø–∏—Å–∫–∏ –ø–æ–≤–∏–Ω–Ω—ñ –±—É—Ç–∏ –æ–¥–Ω–∞–∫–æ–≤–æ—ó –¥–æ–≤–∂–∏–Ω–∏.")
    else:
        segments = []
        pause = AudioSegment.silent(duration=pause_ms)
        length = len(words1) or len(words2)

        audio_1 = make_audio_list(words1, lang_code1)
        audio_2 = make_audio_list(words2, lang_code2)

        if one_by_one:
            for i in range(length):
                if words1:
                    segments.extend([audio_1[i], pause])
                if words2:
                    segments.extend([audio_2[i], pause])
        else:
            if words1:
                for i in range(length):
                    segments.extend([audio_1[i], pause])
            if words2:
                for i in range(length):
                    segments.extend([audio_2[i], pause])

        segments *= repeat_count
        final_audio = sum(segments)
        buffer = BytesIO()
        final_audio.export(buffer, format="mp3")
        buffer.seek(0)

        st.session_state.history.append({
            "lang1": lang1,
            "lang2": lang2,
            "words1": words1,
            "words2": words2,
            "audio": buffer.getvalue()
        })

        st.success("‚úÖ –ê—É–¥—ñ–æ –∑–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ!")
        st.audio(buffer, format="audio/mp3")
        st.download_button("‚¨áÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ MP3", buffer, file_name="translated_words.mp3")

if st.session_state.history:
    st.markdown("## üïò –Ü—Å—Ç–æ—Ä—ñ—è")
    for idx, item in enumerate(reversed(st.session_state.history)):
        st.markdown(f"**–ü–∞—Ä–∞ {len(st.session_state.history)-idx}: {item["lang1"]} ‚Üí {item["lang2"]}**")
        st.audio(item["audio"], format="audio/mp3")
        st.download_button(
            label="‚¨áÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏",
            data=item["audio"],
            file_name=f"history_{len(st.session_state.history)-idx}.mp3",
            key=f"download_{idx}"
        )
